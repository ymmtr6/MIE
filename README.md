# Mathematical Information Engineering

数理情報工学特論

差分進化によるAutoEncoderのハイパーパラメータチューニング

# USAGE

```
$ docker run ymmtr6/mie:cpu
$ python de.py --output output.json
```


# はじめに

深層学習は，近年注目されている機械学習の手法の一つである．
人間の神経細胞からヒントを得たニューラルネットワークを，
多層にして構成されているものをいう．
勾配消失問題や局所最適解に陥る現象を解決し，また，
GPUなどのハードウェア技術の向上もあり，多層に積み重ねた
ニューラルネットワーク，VGG16やResNetなどが登場した．

深層学習の応用範囲は，従来コンピュータビジョン分野において
扱われてきた画像認識，物体検出だけでなく，強化学習と組み合わせたDeep Q-Networkによって作られた囲碁エージェント「AlphaGo」，
機械翻訳と組み合わせたニューラル機械翻訳などがあり，
システムが人間の知覚に匹敵するレベルに到達する為の必須技術となっている．

しかし，ディープニューラルネットワークに関連するモデルでは，
従来の機械学習において扱われていた前処理の大半が不要になった代わりに，
学習率，重み初期値，バイアス，活性化関数，オプティマイザー，正規化など数々のハイパーパラメータが存在する．
モデルの複雑化に伴い，ハイパーパラメータ数も増加する傾向にあり，
手作業や簡単な手法では細かな調整を行うことができない．
一般的に，これらのハイパーパラメータは，経験的（ヒューリスティック）に
値を決めている場合がほとんどであり，これらの値は理論的に証明されていない
ことが多い．

本レポートでは，ニューラルネットワークの学習前に設定しなくてはならない
ハイパーパラメータのチューニングを，差分進化を用いて実現する．
差分進化は，最適化の対象となる問題に対する仮定が少ないメタヒューリスティックな
手法であり，また，最適化の対象となる問題の勾配を用いない為，最適化問題が
微分可能である必要がなくなる手法である．
この為，学習の結果を最適化問題とし，ハイパーパラメータを解候補とすることで
チューニングが実現できると考えた．

# 研究の目的

深層学習分野において，ディープニューラルネットワークのモデルは複雑化の傾向にある．モデルの複雑化に伴い，ハイパーパラメータの数も増加の傾向にある為，手作業のチューニングは難しくなる．また，これらの値は経験的に決められることが多く，問題に対して良い値であるかはわからない．

今回，教師あり学習の中でも入力値と出力値が同じになるため，教師値が用意しやすく，モデルの大きさが小さく，計算量的に簡単になるAutoEncoderに注目し，このモデルのハイパーパラメータチューニングを差分進化を用いて行う．
